{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6GSS-ozDWNf6","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision \n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wqMoJc_DkRGR","outputId":"f71e77f4-e95d-4fbb-b010-e1622d4a488b","trusted":true},"outputs":[],"source":["device = ('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["transform = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize((225,225)),\n","    torchvision.transforms.CenterCrop((224,224)),\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize(mean = [0.5,0.5,0.5], std=[0.5,0.5,0.5])\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["root = './cifar_data/'\n","\n","# Create the directory if it doesn't exist\n","if not os.path.exists(root):\n","    os.makedirs(root)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batch_size = 32\n","num_epoch = 10\n","learning_rate = 0.01\n","momentum = 0.9"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data = torchvision.datasets.CIFAR100(root=root, download = True, train = True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size = batch_size, num_workers = 4)\n","test_data = torchvision.datasets.CIFAR100(root=root, download = True, train = False, transform=transform)\n","test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size = batch_size, num_workers = 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ltypr76UWwrC","trusted":true},"outputs":[],"source":["class block(nn.Module):\n","  def __init__(self, in_channels, out_channels, identity_downsample = None, stride = 1):\n","    super(block, self).__init__()\n","    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n","    self.bn1 =  nn.BatchNorm2d(out_channels)\n","    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n","    self.bn2 =  nn.BatchNorm2d(out_channels)\n","    self.conv3 = nn.Conv2d(out_channels, out_channels*4, kernel_size=1, stride=1, padding=0)\n","    self.bn3 =  nn.BatchNorm2d(out_channels*4)\n","\n","    self.relu = nn.ReLU()\n","    self.identity_downsample = identity_downsample\n","\n","  def forward(self,x):\n","    identity = x\n","\n","    x = self.conv1(x)\n","    x = self.bn1(x)\n","    x = self.relu(x)\n","    x = self.conv2(x)\n","    x = self.bn2(x)\n","    x = self.relu(x)\n","    x = self.conv3(x)\n","    x = self.bn3(x)\n","\n","    if self.identity_downsample is not None:\n","      identity = self.identity_downsample(identity)\n","\n","    x += identity\n","    x = self.relu(x)\n","    return x\n","\n","\n","class ResNet(nn.Module):\n","  def __init__(self, block, image_channels, num_classes, layers):\n","    super(ResNet, self).__init__()\n","    self.in_channels = 64\n","    self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n","    self.bn1 = nn.BatchNorm2d(64)\n","    self.relu = nn.ReLU()\n","    self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","    # Resnet Layers\n","    self.layer1 = self._make_layer(block, layers[0], self.in_channels, 64, stride=1)\n","    self.layer2 = self._make_layer(block, layers[1], self.in_channels, 128, stride=2)\n","    self.layer3 = self._make_layer(block, layers[2], self.in_channels, 256, stride=2)\n","    self.layer4 = self._make_layer(block, layers[3], self.in_channels, 512, stride=2)\n","\n","    self.adaptiveavgpool =  nn.AdaptiveAvgPool2d((1,1))\n","    self.fc = nn.Linear(512*4, num_classes)\n","\n","  def forward(self,x):\n","    x = self.conv1(x)\n","    x = self.bn1(x)\n","    x = self.relu(x)\n","    x = self.max_pool(x)\n","\n","    x = self.layer1(x)\n","    x = self.layer2(x)\n","    x = self.layer3(x)\n","    x = self.layer4(x)\n","    \n","    x =  self.adaptiveavgpool(x)\n","    x = x.reshape(x.shape[0], -1)\n","    x = self.fc(x)\n","\n","    return x\n","\n","  def _make_layer(self, block,num_residual_blocks, in_channels, out_channels, stride):\n","    identity_downsample = None\n","    layers = []\n","\n","    if stride != 1 or self.in_channels != out_channels*4:\n","      identity_downsample = nn.Sequential(nn.Conv2d(in_channels, out_channels*4, kernel_size=1, stride=stride, padding=0), nn.BatchNorm2d(out_channels*4))\n","\n","    layers.append(block(in_channels, out_channels, identity_downsample, stride))\n","    self.in_channels = out_channels * 4 \n","\n","    for i in range(num_residual_blocks-1):\n","      layers.append(block(self.in_channels, out_channels))\n","\n","    return nn.Sequential(*layers)   "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4VmKxj8eG7h","trusted":true},"outputs":[],"source":["def ResNet50(image_channels = 3, num_classes=100):\n","  return ResNet(block, image_channels, num_classes, [3,4,6,3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eQMMU-vhkKB0","outputId":"bb430813-cb7c-405b-e0c8-4d3008f8a7cb","trusted":true},"outputs":[],"source":["model = ResNet50()\n","model.to(device)\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, momentum=momentum )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for epoch in range(num_epoch):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        predicted = model(images)\n","        loss = loss_func(predicted, labels)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if (i+1) % 100 == 0:\n","            print(f\"[{epoch}, {i+1}], loss : {loss}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["total = correct = 0\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        predict = model(images)\n","        predcited_softmax = nn.Softmax(1)(predict)\n","        _, output = torch.max(predcited_softmax, dim=1)\n","        correct += (output == labels).sum().item()\n","        total += labels.size(0)\n","    \n","    print(f\"Accuracy of the Model : {100*(correct/total)}%\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
